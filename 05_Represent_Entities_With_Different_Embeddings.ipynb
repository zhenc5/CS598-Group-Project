{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nHtYS16HN8s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "new_notes = pd.read_pickle(\"data/ner_df.p\")\n",
        "w2vec = Word2Vec.load(\"embeddings/word2vec.model\")"
      ],
      "metadata": {
        "id": "FgoTWjPQHcvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows with empty 'ner' values\n",
        "null_index_list = [i.Index for i in new_notes.itertuples() if len(i.ner) == 0]\n",
        "new_notes.drop(null_index_list, inplace=True)"
      ],
      "metadata": {
        "id": "RmQdN4XQHeAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process NER data\n",
        "med7_ner_data = {}\n",
        "for ii in new_notes.itertuples():\n",
        "    p_id = ii.SUBJECT_ID\n",
        "    ind = ii.Index\n",
        "\n",
        "    try:\n",
        "        new_ner = new_notes.loc[ind].ner\n",
        "    except:\n",
        "        new_ner = []\n",
        "\n",
        "    new_temp = [(k[0], k[1]) for j in new_ner for k in j]\n",
        "\n",
        "    if p_id in med7_ner_data:\n",
        "        med7_ner_data[p_id].extend(new_temp)\n",
        "    else:\n",
        "        med7_ner_data[p_id] = new_temp\n"
      ],
      "metadata": {
        "id": "CE3iEeTgHflr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save processed NER data\n",
        "pd.to_pickle(med7_ner_data, \"data/new_ner_word_dict.pkl\")"
      ],
      "metadata": {
        "id": "ODo5KNAdHhdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean for vectors\n",
        "def mean(a):\n",
        "    return sum(a) / len(a)"
      ],
      "metadata": {
        "id": "rtLIccAaHjmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process Word2Vec embeddings\n",
        "data_types = [med7_ner_data]\n",
        "data_names = [\"new_ner\"]\n",
        "\n",
        "for data, names in zip(data_types, data_names):\n",
        "    new_word2vec = {}\n",
        "    print(\"w2vec starting..\")\n",
        "    for k, v in data.items():\n",
        "        patient_temp = []\n",
        "        if isinstance(v, list):\n",
        "            for i in v:\n",
        "                if isinstance(i, tuple) and len(i) == 2 and isinstance(i[0], str):\n",
        "                    if i[0] in w2vec.wv:\n",
        "                        patient_temp.append(w2vec.wv[i[0]])\n",
        "                    elif len(i[0].split(\" \")) > 1:\n",
        "                        avg = []\n",
        "                        words = i[0].split(\" \")\n",
        "                        num = 0\n",
        "                        for each_word in words:\n",
        "                            if each_word in w2vec.wv:\n",
        "                                temp = w2vec.wv[each_word]\n",
        "                                avg.append(temp)\n",
        "                                num += 1\n",
        "                        if num > 0:\n",
        "                            avg = np.asarray(avg)\n",
        "                            t = np.asarray(list(map(mean, zip(*avg))))\n",
        "                            patient_temp.append(t)\n",
        "        if patient_temp:\n",
        "            new_word2vec[k] = patient_temp\n",
        "\n",
        "    print(len(new_word2vec))\n",
        "    pd.to_pickle(new_word2vec, \"data/\"+names+\"_word2vec_dict.pkl\")"
      ],
      "metadata": {
        "id": "ZHfO9OOAHlCj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}