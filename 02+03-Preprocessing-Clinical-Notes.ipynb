{"cells":[{"cell_type":"markdown","metadata":{"id":"2EhLzc79WbH-"},"source":["#### Extracting Time-Series Features and Preprocessing Clinical Notes"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1eSx7cyINuk1","executionInfo":{"status":"ok","timestamp":1714368132947,"user_tz":300,"elapsed":3851,"user":{"displayName":"Chien-Yun Cheng","userId":"10737011241608399428"}},"outputId":"60610380-ed98-479e-c14f-759bf0c668ed"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["# import libraries\n","import re\n","import os\n","import pandas as pd\n","import numpy as np\n","import nltk\n","from nltk import sent_tokenize, word_tokenize\n","nltk.download('punkt')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"AY45P3n4NKnz","executionInfo":{"status":"ok","timestamp":1714368138763,"user_tz":300,"elapsed":165,"user":{"displayName":"Chien-Yun Cheng","userId":"10737011241608399428"}}},"outputs":[],"source":["## Helper functions for preprocessing text in the data file\n","# This code is taken from https://github.com/kaggarwal/ClinicalNotesICU\n","\n","SECTION_TITLES = re.compile(\n","    r'('\n","    r'ABDOMEN AND PELVIS|CLINICAL HISTORY|CLINICAL INDICATION|COMPARISON|COMPARISON STUDY DATE'\n","    r'|EXAM|EXAMINATION|FINDINGS|HISTORY|IMPRESSION|INDICATION'\n","    r'|MEDICAL CONDITION|PROCEDURE|REASON FOR EXAM|REASON FOR STUDY|REASON FOR THIS EXAMINATION'\n","    r'|TECHNIQUE'\n","    r'):|FINAL REPORT',\n","    re.I | re.M)\n","\n","\n","def getSentences(t):\n","    return list(preprocess_mimic(t))\n","\n","def pattern_repl(matchobj):\n","    \"\"\"\n","    Return a replacement string to be used for match object\n","    \"\"\"\n","    return ' '.rjust(len(matchobj.group(0)))\n","\n","def clean_text(text):\n","    \"\"\"\n","    Clean text\n","    \"\"\"\n","\n","    # Replace [**Patterns**] with spaces.\n","    text = re.sub(r'\\[\\*\\*.*?\\*\\*\\]', pattern_repl, text)\n","    # Replace `_` with spaces.\n","    text = re.sub(r'_', ' ', text)\n","\n","    start = 0\n","    end = find_end(text)\n","    new_text = ''\n","    if start > 0:\n","        new_text += ' ' * start\n","    new_text = text[start:end]\n","\n","    # make sure the new text has the same length of old text.\n","    if len(text) - end > 0:\n","        new_text += ' ' * (len(text) - end)\n","    return new_text\n","\n","def preprocess_mimic(text):\n","    \"\"\"\n","    Preprocess reports in MIMIC-III.\n","    1. remove [**Patterns**] and signature\n","    2. split the report into sections\n","    3. tokenize sentences and words\n","    4. lowercase\n","    \"\"\"\n","    for sec in split_heading(clean_text(text)):\n","        for sent in sent_tokenize(sec):\n","            text = ' '.join(word_tokenize(sent))\n","            yield text.lower()\n","\n","def split_heading(text):\n","    \"\"\"Split the report into sections\"\"\"\n","    start = 0\n","    for matcher in SECTION_TITLES.finditer(text):\n","        # add last\n","        end = matcher.start()\n","        if end != start:\n","            section = text[start:end].strip()\n","            if section:\n","                yield section\n","\n","        # add title\n","        start = end\n","        end = matcher.end()\n","        if end != start:\n","            section = text[start:end].strip()\n","            if section:\n","                yield section\n","\n","        start = end\n","\n","    # add last piece\n","    end = len(text)\n","    if start < end:\n","        section = text[start:end].strip()\n","        if section:\n","            yield section\n","\n","def find_end(text):\n","    \"\"\"Find the end of the report.\"\"\"\n","    ends = [len(text)]\n","    patterns = [\n","        re.compile(r'BY ELECTRONICALLY SIGNING THIS REPORT', re.I),\n","        re.compile(r'\\n {3,}DR.', re.I),\n","        re.compile(r'[ ]{1,}RADLINE ', re.I),\n","        re.compile(r'.*electronically signed on', re.I),\n","        re.compile(r'M\\[0KM\\[0KM')\n","    ]\n","    for pattern in patterns:\n","        matchobj = pattern.search(text)\n","        if matchobj:\n","            ends.append(matchobj.start())\n","    return min(ends)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"6Xk-uBK2Nuk3","executionInfo":{"status":"ok","timestamp":1714368329240,"user_tz":300,"elapsed":156,"user":{"displayName":"Chien-Yun Cheng","userId":"10737011241608399428"}}},"outputs":[],"source":["DATAPATH = \"data/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jAWBwNbHNuk3"},"outputs":[],"source":["# load MIMIC III raw data\n","def load_raw_data(raw_data_dir):\n","  \"\"\"Loads raw data to dataframe/numpy array/tensor\"\"\"\n","  admission_df = pd.read_csv(os.path.join(raw_data_dir, 'ADMISSIONS.csv'))\n","  events_df = pd.read_csv(os.path.join(raw_data_dir, 'NOTEEVENTS.csv'), low_memory = False)\n","  icu_stay_df = pd.read_csv(os.path.join(raw_data_dir, 'ICUSTAYS.csv'))\n","\n","  #print(len(admission_df))\n","  #print(len(events_df))\n","  #print(len(icu_stay_df))\n","\n","  return [admission_df, events_df, icu_stay_df]\n","\n","raw_data = load_raw_data(DATAPATH)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"yYI09N6gNuk3","executionInfo":{"status":"error","timestamp":1714368318640,"user_tz":300,"elapsed":590,"user":{"displayName":"Chien-Yun Cheng","userId":"10737011241608399428"}},"outputId":"93ef9eb8-23d6-46a2-d164-61f30dd35d35"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'raw_data' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-cae8401a0b59>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdf_less_n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'raw_data' is not defined"]}],"source":["# Calculate statistics of MIMIC-III data\n","\n","def calculate_stats(raw_data):\n","  \"\"\"Implement this function to calculate the statistics.\n","  It is encouraged to print out the results.\"\"\"\n","  admission_data = raw_data[0]\n","  note_events_data = raw_data[1]\n","  icu_stay_data = raw_data[2]\n","  print(\"There are a total of \", len(admission_data), \" Admission Data\")\n","  print(\"There are a total of \", len(icu_stay_data), \" ICU Stay Data\")\n","\n","  ## Select Clinical Notes\n","  note_events_data.groupby(note_events_data.CATEGORY).agg(['count'])\n","  note_categories = note_events_data.groupby(note_events_data.CATEGORY).agg(['count']).index\n","  selected_note = []\n","  for category in list(note_categories):\n","    if category != 'Discharge summary':\n","      selected_note.append(category)\n","\n","  ## Create sub notes based on category\n","  sub_notes = note_events_data[note_events_data.CATEGORY.isin(selected_note)]\n","  sub_notes.shape\n","\n","  ## Handle missing chart\n","  missing_chart_notes_idx = []\n","  for note in sub_notes.itertuples():\n","    if isinstance(note.CHARTTIME, str):\n","      continue\n","    if np.isnan(note.CHARTTIME):\n","      missing_chart_notes_idx.append(note.Index)\n","  print(\"{} of notes missing charttime.\".format(len(missing_chart_notes_idx)))\n","  sub_notes.drop(missing_chart_notes_idx, inplace = True)\n","  print(\"sub_notes shape: \", sub_notes.shape)\n","\n","  ## Select based on Time Limit (24 hours)\n","  MIMIC_EXTRACT_DATA = os.path.join(DATAPATH, 'all_hourly_data.h5')\n","  statistic = pd.read_hdf(MIMIC_EXTRACT_DATA, 'patients')\n","  print(\"MIMIC-EXTRACT DATA (Patients Num & Hospital Admission & ICU Admission): \", len(statistic))\n","  TIMELIMIT = 1 ## 1 day\n","  statistic.shape\n","  statistic.head()\n","  new_stats = statistic.reset_index()\n","  new_stats.rename(columns = {\"subject_id\": \"SUBJECT_ID\", \"hadm_id\": \"HADM_ID\"}, inplace = True)\n","  print(\"new_stats shape: \", new_stats.shape, \"\\nsub_notes shape: \", sub_notes.shape)\n","  df_adm_notes = pd.merge(sub_notes[['ROW_ID','SUBJECT_ID','HADM_ID','CHARTTIME', 'CATEGORY', 'TEXT']],\n","                          new_stats[['SUBJECT_ID','HADM_ID','icustay_id','age','admittime','dischtime', 'deathtime', 'intime', 'outtime', 'los_icu', 'mort_icu', 'mort_hosp', 'hospital_expire_flag', 'hospstay_seq', 'max_hours']],\n","                          on = ['SUBJECT_ID'],\n","                          how = 'left')\n","  df_adm_notes.head()\n","  df_adm_notes['CHARTTIME'] = pd.to_datetime(df_adm_notes['CHARTTIME'])\n","  df_less_n = df_adm_notes[((df_adm_notes['CHARTTIME'] - df_adm_notes['intime']).dt.total_seconds() / (24*60*60)) < TIMELIMIT]\n","  print(\"df_less_n.shape: \", df_less_n.shape)\n","\n","  # Save clinical notes\n","  pd.to_pickle(df_less_n, os.path.join(DATAPATH, 'sub_notes.p'))\n","  return df_less_n\n","\n","state = calculate_stats(raw_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9lC7u4c2Nuk3","outputId":"b691f4c6-aa4d-47db-e6fd-a4b9b48c8e6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Clinical notes shape:  (252576, 20)\n","Preprocessed Data shape:  (252576, 5)\n"]}],"source":["# Process raw data\n","\n","def process_data(raw_data):\n","  \"\"\"Preprocess the text in the clinical notes\"\"\"\n","  clinical_notes = pd.read_pickle(os.path.join(DATAPATH, 'sub_notes.p'))\n","  print(\"Clinical notes shape: \", clinical_notes.shape)\n","\n","  eliminate_notes = clinical_notes[clinical_notes.SUBJECT_ID.notnull()]\n","  eliminate_notes = eliminate_notes[eliminate_notes.CHARTTIME.notnull()]\n","  eliminate_notes = eliminate_notes[eliminate_notes.TEXT.notnull()]\n","\n","  eliminate_notes = eliminate_notes[['SUBJECT_ID', 'HADM_ID_y', 'CHARTTIME', 'TEXT']]\n","  eliminate_notes['preprocessed_text'] = None\n","\n","  for notes in eliminate_notes.itertuples():\n","    text = notes.TEXT\n","    eliminate_notes.at[notes.Index, 'preprocessed_text'] = getSentences(text)\n","\n","  pd.to_pickle(eliminate_notes, os.path.join(DATAPATH, 'preprocessed_notes.p'))\n","  print(\"Preprocessed Data shape: \", eliminate_notes.shape)\n","  return eliminate_notes\n","\n","processed_data = process_data(raw_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJYDAfnzNuk3","outputId":"e05b1ed1-37eb-4400-aabb-d55cc4eb64ee"},"outputs":[{"data":{"text/plain":["Index(['SUBJECT_ID', 'HADM_ID_y', 'CHARTTIME', 'TEXT', 'preprocessed_text'], dtype='object')"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["processed_data.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KmLAeRg6Nuk4","outputId":"a58526b1-308e-4c99-f8b5-472dfa9be58f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SUBJECT_ID</th>\n","      <th>HADM_ID_y</th>\n","      <th>CHARTTIME</th>\n","      <th>TEXT</th>\n","      <th>preprocessed_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>25</th>\n","      <td>27866</td>\n","      <td>109679.0</td>\n","      <td>2143-04-09 03:22:00</td>\n","      <td>Ms. [**Known lastname 1170**] is an 83 yo F w/...</td>\n","      <td>[ms. is an 83 yo f w/pmhx sx for cll , hyperte...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>27866</td>\n","      <td>109679.0</td>\n","      <td>2143-04-09 03:22:00</td>\n","      <td>Ms. [**Known lastname 1170**] is an 83 yo F w/...</td>\n","      <td>[ms. is an 83 yo f w/pmhx sx for cll , hyperte...</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>31975</td>\n","      <td>165003.0</td>\n","      <td>2138-02-11 05:09:00</td>\n","      <td>Pneumonia, other\\n   Assessment:\\n   Afebrile,...</td>\n","      <td>[pneumonia , other assessment : afebrile , wit...</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>29075</td>\n","      <td>179159.0</td>\n","      <td>2116-02-06 00:25:00</td>\n","      <td>Chief Complaint:  GI bleeding\\n   HPI:\\n   67M...</td>\n","      <td>[chief complaint : gi bleeding hpi : 67m w/ h/...</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>29075</td>\n","      <td>179159.0</td>\n","      <td>2116-02-06 00:25:00</td>\n","      <td>Chief Complaint:  GI bleeding\\n   HPI:\\n   67M...</td>\n","      <td>[chief complaint : gi bleeding hpi : 67m w/ h/...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    SUBJECT_ID  HADM_ID_y           CHARTTIME  \\\n","25       27866   109679.0 2143-04-09 03:22:00   \n","26       27866   109679.0 2143-04-09 03:22:00   \n","39       31975   165003.0 2138-02-11 05:09:00   \n","45       29075   179159.0 2116-02-06 00:25:00   \n","46       29075   179159.0 2116-02-06 00:25:00   \n","\n","                                                 TEXT  \\\n","25  Ms. [**Known lastname 1170**] is an 83 yo F w/...   \n","26  Ms. [**Known lastname 1170**] is an 83 yo F w/...   \n","39  Pneumonia, other\\n   Assessment:\\n   Afebrile,...   \n","45  Chief Complaint:  GI bleeding\\n   HPI:\\n   67M...   \n","46  Chief Complaint:  GI bleeding\\n   HPI:\\n   67M...   \n","\n","                                    preprocessed_text  \n","25  [ms. is an 83 yo f w/pmhx sx for cll , hyperte...  \n","26  [ms. is an 83 yo f w/pmhx sx for cll , hyperte...  \n","39  [pneumonia , other assessment : afebrile , wit...  \n","45  [chief complaint : gi bleeding hpi : 67m w/ h/...  \n","46  [chief complaint : gi bleeding hpi : 67m w/ h/...  "]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["processed_data.head()"]}],"metadata":{"colab":{"provenance":[{"file_id":"1MGxB_J2TvhAANcQG8VNMvQp1QdQrcxWb","timestamp":1711309692552},{"file_id":"1oAKqszNlwEZwPa_BjHPqfcoWlikYBpi5","timestamp":1709153069464}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}