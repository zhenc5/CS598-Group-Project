{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjoROCQXbaoO"
      },
      "source": [
        "# CS-598 DL4H Reproducibility Project: \"Improving clinical outcome predictions using convolution over medical entities with multimodal learning\"\n",
        "\n",
        "Team 34: Kristine Cheng (cycheng4), Vanessa Chen (zhenc5), Sophia Yu (sophiay3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrHvwHU6Vl4v"
      },
      "source": [
        "## Project Location\n",
        "* Google Drive Link: https://drive.google.com/drive/folders/1nlDMRbCBY27ygu5EKwvnyUR3SDempmbJ?usp=drive_link\n",
        "\n",
        "* Github Link: https://github.com/zhenc5/CS598-Group-Project\n",
        "\n",
        "* Video presentation on Youtube Link:https://drive.google.com/file/d/1ME7jcAtdW8Zc9a09tRz-feuGr8HITqM5/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlv6knX04FiY"
      },
      "source": [
        "## Mount Notebook to Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfk8Zrul_E8V",
        "outputId": "7c718f59-cf4a-4ef6-c862-38e7451e7a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ0sNuMePBXx"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "*   **Background of the problem**\n",
        "\n",
        "  It is crucial to assess a patientâ€™s health by looking at their medical tests and predicting how they might fare during their stay in the ICU. The type of problem addressed in the paper is clinical outcome prediction, specifically predicting mortality (in-hospital & in-ICU) and length of ICU stay (LOS) (>3 days & >7 days).\n",
        "\n",
        "  ![task_prediction.png](https://drive.google.com/uc?export=view&id=1Mfvjp_7vDHGOAF5SqUyOnfMb2tQQuhUM)\n",
        "  \n",
        "  Figure 1. Definitions of the clinical prediction tasks (as shown in the paper [1])\n",
        "\n",
        "  Predicting clinical outcomes is an important problem in healthcare, because it can help hospitals and healthcare providers reduce healthcare costs, improve patient outcomes by determining treatment methods, and optimize healthcare resource utilization. By accurately predicting LOS and mortality, healthcare providers can provide targeted interventions to those at high risk, thereby leading to better patient outcomes and more efficient use of hospital resources.\n",
        "\n",
        "  One of the major difficulties associated with predicting these clinical outcomes using electronic health records (EHR) is in standardizing the preprocessing steps, such as in the handling of missing data and outliers, unit conversions, and the transformation of raw data into usable features to be used in deep learning algorithms [1].  Additionally, previous studies that aim to predict these clinical outcomes have used only structured patient data, such as historical patient diagnoses (ICD codes) [5, 6], lab results and other measurements taken in the ICU [7-9]. To improve the accuracy of the predictions, unstructured clinical notes can be added to the deep learning model. However, extracting medical entities from unstructured clinical notes presents its own challenges because it is free text usually containing grammatical errors, shorthand, medical jargon and redundant information [1].\n",
        "\n",
        "  Some state-of-the-art deep learning algorithm methods for using EHR data to predict clinical outcomes include Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) because they are most effective at learning from sequence data. Lipton et al. demonstrated the effectiveness of a LSTM to model clinical data, specifically to classify 128 diagnoses using 13 clinical measurements [10]. Choi et al. showed promising results in predicting multi-label diagnosis for a patient's next visit using a GRU-based model called DoctorAI [5].\n",
        "\n",
        "*  **Paper explanation**\n",
        "\n",
        "  Electronic Health Record (EHR) data is commonly used in deep learning applications for clinical outcome predictions. However, traditional approaches often overlook the unstructured data within EHR, such as clinical notes and radiology. Bardak and Tan address [1]  this issue by exploring methods to improve two different common risk prediction tasks - mortality and length of ICU stay (LOS). The paper proposes a deep learning method that involves extracting medical entities from clinical notes and integrating them into prediction models using a convolution-based multimodal architecture. Additionally, they evaluated different embedding techniques, such as Word2Vec and FastText on medical entities.\n",
        "\n",
        "  The innovative feature in the proposed method in the paper is the use of CNN architecture to capture local patterns in the EHR data and medical entity embeddings of the clinical notes, and then to combine the learned features from the CNN with features extracted from the timeseries data to make its predictions.\n",
        "\n",
        "  The results show that the proposed method outperforms the baseline models on all 4 clinical outcome predictions in terms of AUCROC, AURPRC, and F1 score, with the exception of LOS >7 days where the F1 score was greater for the baseline model.\n",
        "\n",
        "  Overall, the paper makes an important contribution to the research regime of clinical outcome predictions by introducing a novel approach that not only enhances the accuracy of these predictions but also has the adaptability to be applied to other clinical outcome prediction tasks. The implementation of convolution on medical entities, extracted from EHR clinical notes, in conjunction with multimodal learning, signifies an important step forward in the development of predictive models for clinical outcomes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uygL9tTPSVHB"
      },
      "source": [
        "## Scope of Reproducibility:\n",
        "\n",
        "Below lists the hypotheses to be tested and the corresponding experiments that will be run:\n",
        "  1. The proposed convolution-based multimodal architecture outperforms the baseline multimodal architecture for each of the 4 clinical outcome prediction tasks.\n",
        "    * Various embedding techniques, such as Word2Vec, FastText, and the concatenation of Word2Vec and FastText embeddings on the EHR clinical notes, will also be compared among the baseline multimodel architecture and the proposed convolution-based architecture.\n",
        "\n",
        "  2. The baseline multimodal model shows an improved prediction performance compared to the baseline time-series GRU on each of the 4 clinical outcome tasks.\n",
        "    * Various embedding techniques, such as Word2Vec, FastText, and the concatenation of Word2Vec and FastText embeddings on the EHR clinical notes, will also be compared among the baseline models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      },
      "source": [
        "## Methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbLlAaK18dHa"
      },
      "source": [
        "### Environment Setup\n",
        "- Python version 3.10.12\n",
        "- Dependent packages needed:\n",
        "  - numpy\n",
        "  - pandas\n",
        "  - tables\n",
        "  - nltk\n",
        "  - spacy\n",
        "  - gensim\n",
        "  - keras==2.10.0\n",
        "  - scipy==1.10.1\n",
        "  - tensorflow\n",
        "  - scikit-learn\n",
        "  - (med7 pre-trained model) https://huggingface.co/kormilitzin/en_core_med7_lg/resolve/main/en_core_med7_lg-any-py3-none-any.whl\n",
        "\n",
        "To install the dependencies, use the following command:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1mZtOm3Lx91"
      },
      "outputs": [],
      "source": [
        "# pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80pPm-qAL7_r"
      },
      "source": [
        "Then import the necessary packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu61Jp1xrnKk",
        "outputId": "0dbbbb18-0b3e-4885-8a64-3d6ccf959132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary packages\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import re\n",
        "import spacy\n",
        "from nltk import sent_tokenize, word_tokenize, punkt\n",
        "\n",
        "from gensim.models import Word2Vec, FastText\n",
        "\n",
        "import collections\n",
        "import gc\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Flatten, Dense, Dropout, Input, concatenate, Activation, Concatenate, LSTM, GRU\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv1D, BatchNormalization, Convolution1D\n",
        "from keras.layers import UpSampling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D, MaxPool1D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, History, ReduceLROnPlateau\n",
        "from tensorflow.python.keras.utils import np_utils\n",
        "from tensorflow.python.keras.backend import set_session, clear_session, get_session\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
        "\n",
        "from logging import NullHandler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NbPHUTMbkD3"
      },
      "source": [
        "###  Data\n",
        "\n",
        "**Data download instructions**\n",
        "\n",
        "In order to implement the paper's code, 3 folders must first be created in the directory and named \"data\", \"embeddings\", and \"results\". Within the \"results\" folder, 2 new folders called \"cnn\" and \"multimodal\" must also be created.\n",
        "\n",
        "* Download the MIMIC-III dataset (specifically ADMISSIONS.csv, NOTEEVENTS.csv, ICUSTAYS.csv) via https://mimic.physionet.org/ and place in the \"data\" folder\n",
        "* Download the MIMIC-Extract implementation (called \"all_hourly_data.h5\") via https://github.com/MLforHealth/MIMIC_Extract and place in the \"data\" folder\n",
        "* The med7 implementation should already be installed via requirements.txt. Source: https://github.com/kormilitzin/med7\n",
        "* Download the pre-trained Word2Vec and FastText embeddings via https://github.com/kexinhuang12345/clinicalBERT and place in the \"embeddings\" folder\n",
        "\n",
        "**Source of the data**\n",
        "\n",
        "The data is collected from running MIMIC-III data [2-4] through MIMIC-Extract Pipeline. Since we only wished to use the output of this pipeline, we were able to directly download a preprocessed version with default parameters from their Github page [4, 11]. The dataset is stored in the \"data\" folder as all_hourly_data.h5. We also use ADMISSIONS.csv, NOTEEVENTS.csv, ICUSTAYS.csv from the MIMIC-III dataset.  \n",
        "\n",
        "\n",
        "**Statistics**\n",
        "\n",
        "\n",
        "**For the time series data:**\n",
        "\n",
        "The MIMIC-III dataset contains EHR data of 58,976 unique hospital admissions and 61,532 ICU admissions from 46,520 patients.\n",
        "\n",
        "The MIMIC-Extract dataset contains a patient's first ICU visit and already eliminates patients with ages < 15 years and where the LOS is not between 12 hours and 10 days [1]. It contains 34,472 patients and 104 time-series variables.\n",
        "\n",
        "Then, we drop any patients who do not have at least 30 hours of data. We also drop any clinical notes that do not contain chart time information and any patients that do not have any clinical notes in 24 hours. This leads to a final cohort, after clinical note elimination, of 23,944 records of patients, hospital admissions, and ICU admissions.\n",
        "\n",
        "**For the medical entities data:**\n",
        "\n",
        "The paper reported the final unique counts of the 7 medical entities (Drug, Strength, Form, Route, Dosage, Frequency, Duration) as being 18268, 10749, 597, 1193, 7239, 3344, and 1185 respectfully.\n",
        "\n",
        "**Data process**\n",
        "\n",
        "By feeding data through first 24 hour features, the data should be split into three different csv files named ADMISSION, NOTEEVENTS, ICUSTAYS respectfully and placed in the \"data\" folder.\n",
        "\n",
        "The medical entities from the clinical notes will be used to enhance the prediction performance. In order to extract the medical embeddings, we used a pre-trained clinical named-entity recognition (NER) model, med7 [12], which extracts 7 different entities (Drug, Strength, Duration, Route, Form, Dosage, Frequency). Then, we used the pre-trained Word2Vec and FastText embedding techniques [13] (stored in the \"embeddings\" folder) to convert the medical entities into word representations.\n",
        "\n",
        "The train/valid/test split, for all clinical tasks, is based on class\n",
        "distribution with 70%/10%/20% ratio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96QwHP65ikfV"
      },
      "source": [
        "### Data Preprocessing Steps"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATAPATH = '/content/drive/MyDrive/CS598_Project/data'"
      ],
      "metadata": {
        "id": "OZToPaeBDIvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfYdP_s5t9mw"
      },
      "source": [
        "#### 1. Extracting Time-Series Features and Preprocessing Clinical Notes\n",
        "\n",
        "This step was executed locally on a PC and the ouput \"preprocessed_notes.p\" was uploaded to the data folder. The code is provided in \"01-Extract-Timeseries-Features.ipynb\" and \"02+03-Preprocessing-Clinical-Notes.ipynb\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "841yC__xlLL2"
      },
      "outputs": [],
      "source": [
        "MIMIC_EXTRACT_DATA = os.path.join(DATAPATH, 'all_hourly_data.h5')\n",
        "statistic = pd.read_hdf(MIMIC_EXTRACT_DATA, 'patients')\n",
        "print(f\"MIMIC-EXTRACT DATA (# of Patients & Hospital Admission & ICU Admission): {len(statistic)}\")\n",
        "\n",
        "# Check Time Series Data\n",
        "lvl2_train_imputer = pd.read_pickle(os.path.join(DATAPATH, \"lvl2_imputer_train.pkl\"))\n",
        "lvl2_dev_imputer = pd.read_pickle(os.path.join(DATAPATH, \"lvl2_imputer_dev.pkl\"))\n",
        "lvl2_test_imputer = pd.read_pickle(os.path.join(DATAPATH,\"lvl2_imputer_test.pkl\"))\n",
        "Ys = pd.read_pickle(os.path.join(DATAPATH, \"Ys.pkl\"))\n",
        "\n",
        "patients_ids = []\n",
        "for entry in Ys.index:\n",
        "  patients_ids.append(entry[0])\n",
        "\n",
        "print(f\"MIMIC-EXTRACT DATA after preprocessing dataset (# of Patients & Hospital Admission & ICU Admission): {len(patients_ids)}\")\n",
        "\n",
        "print(\"Shape of train, dev, test datasets: {}, {}, {}.\".format((lvl2_train_imputer.shape), (lvl2_dev_imputer.shape), (lvl2_test_imputer.shape)))\n",
        "print(\"After applying time series feature (24 hours), train, dev, and test statistic: {}, {}, {}\".format((lvl2_train_imputer.shape[0] / 24), (lvl2_dev_imputer.shape[0] / 24), (lvl2_test_imputer.shape[0] / 24)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASZEJ41WvA7y"
      },
      "source": [
        "#### 2. Extract Medical Entities in Clinical Notes\n",
        "This step was executed locally on a PC, and the resulting output file \"ner_df.p\" was uploaded to the data folder. The code for this process is provided in the notebook titled \"04 - Apply-med7-on-Clinical-Notes.ipynb.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoeOfk20ndtE"
      },
      "outputs": [],
      "source": [
        "med7_ner_data = pd.read_pickle(os.path.join(DATAPATH, 'new_ner_word_dict.pkl'))\n",
        "\n",
        "# Check that med7 has 7 different entities\n",
        "unique_categories = set()\n",
        "\n",
        "for values in med7_ner_data.values():\n",
        "    for item in values:\n",
        "        category = item[1]\n",
        "        unique_categories.add(category)\n",
        "\n",
        "print(f\"Entities in med7 NER model: {unique_categories}\\n\")\n",
        "\n",
        "# Print the unique counts of each entity\n",
        "unique_values_per_category = {category: set() for category in unique_categories}\n",
        "\n",
        "for values in med7_ner_data.values():\n",
        "    for item in values:\n",
        "        value, category = item\n",
        "        unique_values_per_category[category].add(value)\n",
        "\n",
        "print(\"Unique count for each med7 entity:\")\n",
        "for category, unique_values in unique_values_per_category.items():\n",
        "    print(f\"{category}: {len(unique_values)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQs58NoJQHnI"
      },
      "source": [
        "#### 3. Represent Entities with Different Embeddings\n",
        "\n",
        "This step was executed locally on a PC and the outputs \"new_ner_word_dict.pkl\", \"new_ner_word2vec_dict.pkl\", \"new_ner_fasttext_dict.pkl\", and \"new_ner_combined_dict.pkl\" were uploaded to the data folder. The code is provided in \"05-Represent-Entities-With-Different-Embeddings.ipynb.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8fFD5uiu15U",
        "outputId": "0caafab2-bc30-4300-83d4-866ac7bf035a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Word2Vec embeddings: 31732\n",
            "Number of Fast Text embeddings: 31461\n",
            "Number of concatenated embeddings (Word2Vec + FastText)): 32108\n"
          ]
        }
      ],
      "source": [
        "w2v = pd.read_pickle(os.path.join(DATAPATH, \"new_ner_word2vec_dict.pkl\"))\n",
        "ft = pd.read_pickle(os.path.join(DATAPATH, \"new_ner_fasttext_dict.pkl\"))\n",
        "combined = pd.read_pickle(os.path.join(DATAPATH, \"new_ner_combined_dict.pkl\"))\n",
        "\n",
        "print(f\"Number of Word2Vec embeddings: {len(w2v)}\")\n",
        "print(f\"Number of Fast Text embeddings: {len(ft)}\")\n",
        "print(f\"Number of concatenated embeddings (Word2Vec + FastText)): {len(combined)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izOriQcNvkdM"
      },
      "source": [
        "#### 4. Create Timeseries Data\n",
        "\n",
        "This step was executed locally on a PC and the output files were uploaded to the data folder. The code is provided in \"06-Create-Timeseries-Data.ipynb.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWjybS7jxX_N"
      },
      "outputs": [],
      "source": [
        "#Output files created in \"06-Create-Timeseries-Data.ipynb.\"\n",
        "\n",
        "new_train_ids = pd.read_pickle(os.path.join(DATAPATH, \"new_train_ids.pkl\"))\n",
        "new_dev_ids = pd.read_pickle(os.path.join(DATAPATH, \"new_dev_ids.pkl\"))\n",
        "new_test_ids = pd.read_pickle(os.path.join(DATAPATH, \"new_test_ids.pkl\"))\n",
        "\n",
        "x_train = pd.read_pickle(os.path.join(DATAPATH, \"new_x_train.pkl\"))\n",
        "x_dev = pd.read_pickle(os.path.join(DATAPATH, \"new_x_dev.pkl\"))\n",
        "x_test = pd.read_pickle(os.path.join(DATAPATH, \"new_x_test.pkl\"))\n",
        "\n",
        "y_train = pd.read_pickle(os.path.join(DATAPATH, \"new_y_train.pkl\"))\n",
        "y_dev = pd.read_pickle(os.path.join(DATAPATH, \"new_y_dev.pkl\"))\n",
        "y_test = pd.read_pickle(os.path.join(DATAPATH, \"new_y_test.pkl\"))\n",
        "\n",
        "print(\"new_train_ids size:\", len(new_train_ids))\n",
        "print(\"new_dev_ids size:\", len(new_dev_ids))\n",
        "print(\"new_test_ids size:\", len(new_test_ids))\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"x_dev shape:\", x_dev.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_dev shape:\", y_dev.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3muyDPFPbozY"
      },
      "source": [
        "##   Model\n",
        "\n",
        "The execution of the models below were all performed locally on a PC and the output is saved in the results folder. The full code of the models can be found in the notebooks \"07-Timeseries-Baseline.ipynb\", \"08-Multimodal-Baseline.ipynb\", and \"09-Proposed-Model.ipynb\".\n",
        "\n",
        "To demonstrate the implementation, we have have reduced the epoch number from 100 as stated in the original paper to 3 in this notebook, as well as the iteration number from 11 to 2. We also commented out the fasttext and combined embeddings to reduce runtime. The full code contains all 3 embeddings.\n",
        "\n",
        "The inspiration for the figures explaining the model architecture were all taken from the original paper.\n",
        "\n",
        " *Citation of original paper:*\n",
        "\n",
        "*Bardak B, Tan M, \"Improving clinical outcome predictions using convolution over medical entities with multimodal learning\", Artificial Intelligence in Medicine, 2021, 117:0933-3657, doi:https://doi.org/10.1016/j.artmed.2021.102112.*\n",
        "\n",
        "*Link to original paper's repository:*\n",
        "\n",
        "https://github.com/tanlab/ConvolutionMedicalNer/tree/master"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import datasets\n",
        "type_of_ner = \"new\"\n",
        "x_train_lstm = pd.read_pickle(os.path.join(DATAPATH, type_of_ner+\"_x_train.pkl\"))\n",
        "x_dev_lstm = pd.read_pickle(os.path.join(DATAPATH, type_of_ner+\"_x_dev.pkl\"))\n",
        "x_test_lstm = pd.read_pickle(os.path.join(DATAPATH, type_of_ner+\"_x_test.pkl\"))\n",
        "\n",
        "y_train = pd.read_pickle(os.path.join(DATAPATH, type_of_ner+\"_y_train.pkl\"))\n",
        "y_dev = pd.read_pickle(os.path.join(DATAPATH, type_of_ner+\"_y_dev.pkl\"))\n",
        "y_test = pd.read_pickle(os.path.join(DATAPATH, type_of_ner+\"_y_test.pkl\"))\n",
        "\n",
        "ner_word2vec = pd.read_pickle(os.path.join(DATAPATH, type_of_ner+\"_ner_word2vec_limited_dict.pkl\"))\n",
        "ner_fasttext = pd.read_pickle(os.path.join(DATAPATH, type_of_ner+\"_ner_fasttext_limited_dict.pkl\"))\n",
        "ner_concat = pd.read_pickle(os.path.join(DATAPATH, type_of_ner+\"_ner_combined_limited_dict.pkl\"))\n",
        "\n",
        "train_ids = pd.read_pickle(os.path.join(DATAPATH, type_of_ner+\"_train_ids.pkl\"))\n",
        "dev_ids = pd.read_pickle(os.path.join(DATAPATH, type_of_ner+\"_dev_ids.pkl\"))\n",
        "test_ids = pd.read_pickle(os.path.join(DATAPATH, type_of_ner+\"_test_ids.pkl\"))\n"
      ],
      "metadata": {
        "id": "mHGYBXP-OMl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTmQ0Cpklsyb"
      },
      "source": [
        "### 1. Time-series Baseline\n",
        "\n",
        "We use a Gated Recurrent Units (GRU) architecture to capture the temporal information between patient features. The GRU model has 2 gates, a reset gate, and an update gate. Predictions on mortality and LOS are done with a sigmoid classifier on 1 layer of GRU with 256 hidden units.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=11JItGwXIa0Iy2AUElXfhrcRX8P3KBgrx\"\n",
        "     align=\"center\"\n",
        "     width=\"500\" />\n",
        "\n",
        "Figure 2. Overview of time-series model architecture for predicting the In-Hospital Mortality, In-ICU Mortality, LOS >3, and LOS >7. The MIMIC-Extract pipeline extracts the time series features for the GRU model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhY5Fx2DlPWu"
      },
      "outputs": [],
      "source": [
        "class TimeSeriesModel:\n",
        "    def __init__(self, type_of_ner):\n",
        "        self.type_of_ner = type_of_ner\n",
        "\n",
        "    def reset_keras(self, model):\n",
        "        sess = get_session()\n",
        "        clear_session()\n",
        "        sess.close()\n",
        "        sess = get_session()\n",
        "\n",
        "        try:\n",
        "            del model # this is from global space - change this as you need\n",
        "        except:\n",
        "            pass\n",
        "        gc.collect() # if it's done something you should see a number being outputted\n",
        "\n",
        "    def make_prediction_timeseries(self, model, test_data):\n",
        "        probs = model.predict(test_data)\n",
        "        y_pred = [1 if i>=0.5 else 0 for i in probs]\n",
        "        return probs, y_pred\n",
        "\n",
        "    def save_scores_timeseries(self, predictions, probs, ground_truth, model_name,\n",
        "                               problem_type, iteration, hidden_unit_size, type_of_ner):\n",
        "\n",
        "        auc = roc_auc_score(ground_truth, probs)\n",
        "        auprc = average_precision_score(ground_truth, probs)\n",
        "        acc   = accuracy_score(ground_truth, predictions)\n",
        "        F1    = f1_score(ground_truth, predictions)\n",
        "\n",
        "        result_dict = {}\n",
        "        result_dict['auc'] = auc\n",
        "        result_dict['auprc'] = auprc\n",
        "        result_dict['acc'] = acc\n",
        "        result_dict['F1'] = F1\n",
        "\n",
        "        file_name = str(hidden_unit_size)+\"-\"+model_name+\"-\"+problem_type+\"-\"+str(iteration)+\"-\"+type_of_ner+\".p\"\n",
        "\n",
        "        result_path = \"/content/drive/MyDrive/CS598_Project/results/\"\n",
        "        pd.to_pickle(result_dict, os.path.join(result_path, file_name))\n",
        "\n",
        "        print(\"AUC: {}, AUPRC: {}, Accuracy: {}, F1 Score: {}\".format(auc, auprc, acc, F1))\n",
        "\n",
        "    def timeseries_model(self, layer_name, number_of_unit):\n",
        "        K.clear_session()\n",
        "        sequence_input = Input(shape=(24,104),  name = \"timeseries_input\")\n",
        "\n",
        "        if layer_name == \"LSTM\":\n",
        "            x = LSTM(number_of_unit)(sequence_input)\n",
        "        else:\n",
        "            x = GRU(number_of_unit)(sequence_input)\n",
        "\n",
        "        #logits_regularizer = tf.keras.regularizers.l2(0.01)\n",
        "        logits_regularizer = keras.regularizers.l2(0.01)\n",
        "        sigmoid_pred = Dense(1, activation='sigmoid',use_bias=False,\n",
        "                             kernel_initializer=tf.keras.initializers.GlorotUniform(),\n",
        "                             kernel_regularizer=logits_regularizer)(x)\n",
        "\n",
        "        model = Model(inputs=sequence_input, outputs=sigmoid_pred)\n",
        "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "        return model\n",
        "\n",
        "    def train_models(self):\n",
        "        epoch_num = 3\n",
        "        model_patience = 3\n",
        "        monitor_criteria = 'val_loss'\n",
        "        batch_size = 128\n",
        "\n",
        "        unit_sizes = [256]\n",
        "        iter_num = 2\n",
        "        target_problems = ['mort_hosp', 'mort_icu', 'los_3', 'los_7']\n",
        "        layers = [\"GRU\"]\n",
        "\n",
        "        for each_layer in layers:\n",
        "            print(\"Layer: \", each_layer)\n",
        "            for each_unit_size in unit_sizes:\n",
        "                print(\"Hidden unit: \", each_unit_size)\n",
        "                for iteration in range(1, iter_num):\n",
        "                    print(\"Iteration number: \", iteration)\n",
        "                    print(\"=============================\")\n",
        "\n",
        "                    for each_problem in target_problems:\n",
        "                        print (\"Problem type: \", each_problem)\n",
        "                        print (\"__________________\")\n",
        "\n",
        "\n",
        "                        early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
        "                        best_model_name = str(each_layer)+\"-\"+str(each_unit_size)+\"-\"+str(each_problem)+\"-\"+\"best_model.keras\"\n",
        "                        checkpoint = ModelCheckpoint(best_model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "                        callbacks = [early_stopping_monitor, checkpoint]\n",
        "\n",
        "                        model = self.timeseries_model(each_layer, each_unit_size)\n",
        "                        model.fit(x_train_lstm, y_train[each_problem], epochs=epoch_num, verbose=1,\n",
        "                                  validation_data=(x_dev_lstm, y_dev[each_problem]), callbacks=callbacks, batch_size= batch_size)\n",
        "\n",
        "                        model.load_weights(best_model_name)\n",
        "\n",
        "                        probs, predictions = self.make_prediction_timeseries(model, x_test_lstm)\n",
        "                        #save_scores_timeseries(predictions, probs, y_test[each_problem].values,str(each_layer),\n",
        "                        #                       each_problem, iteration, each_unit_size,type_of_ner)\n",
        "                        self.reset_keras(model)\n",
        "                        #del model\n",
        "                        clear_session()\n",
        "                        gc.collect()\n",
        "\n",
        "model = TimeSeriesModel(type_of_ner)\n",
        "model.train_models()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE2Y_Hy4mCcv"
      },
      "source": [
        "### 2. Multimodal Baseline\n",
        "\n",
        "The multimodal approach tries to improve upon the prediction performance by  having 2 inputs. One is the time-series features derived from the GRU model (explained in the time series baseline model section). The other is the average representations of the medical entities derived from the patients' clinical notes. The 2 inputs are merged into a fully connected layer with 256 hidden units and predictions are done with a sigmoid classifier.\n",
        "\n",
        "We use the pre-trained NER model, med7, to extract different named medical entities and represent them with 3 different embedding methods (a pretrained Word2Vec model, a pretrained FastText model, and the combination of the two).\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Roik2z3jOon_BXq-AOdr6z2ddytSIIPO\"\n",
        "     align=\"center\"\n",
        "     width=\"700\" />\n",
        "\n",
        "Figure 3. Overview of multimodal architecture for predicting the In-Hospital Mortality, In-ICU Mortality, LOS >3, and LOS >7. The MIMIC-Extract pipeline extracts the time series features for the GRU model. We also pass the preprocessed clinical notes through med7 to get the NER entities, which in turn are passed through different word embeddings to get the medical entity representations. An averaging of these representations gives a low-dimensional representation. Finally, we combine the time-series features with the low-dimensional medical entities to pass through a Dense layer (256 hidden units) in order to make a binary prediction on the 4 clinical tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mok8dEygmJ5_"
      },
      "outputs": [],
      "source": [
        "class MultimodalModel:\n",
        "    def __init__(self, type_of_ner):\n",
        "        self.type_of_ner = type_of_ner\n",
        "\n",
        "    def reset_keras(self, model):\n",
        "        sess = get_session()\n",
        "        clear_session()\n",
        "        sess.close()\n",
        "        sess = get_session()\n",
        "\n",
        "        try:\n",
        "            del model # this is from global space - change this as you need\n",
        "        except:\n",
        "            pass\n",
        "        gc.collect() # if it's done something you should see a number being outputted\n",
        "\n",
        "    def create_dataset(self, dict_of_ner):\n",
        "        \"\"\"create the dataset\"\"\"\n",
        "        temp_data = []\n",
        "        for k, v in sorted(dict_of_ner.items()):\n",
        "            temp = []\n",
        "            for embed in v:\n",
        "                temp.append(embed)\n",
        "            temp_data.append(np.mean(temp, axis = 0))\n",
        "        return np.asarray(temp_data)\n",
        "\n",
        "    def make_prediction_multi_avg(self, model, test_data):\n",
        "        probs = model.predict(test_data)\n",
        "        y_pred = [1 if i>=0.5 else 0 for i in probs]\n",
        "        return probs, y_pred\n",
        "\n",
        "    def save_scores_multi_avg(self, predictions, probs, ground_truth, embed_name, problem_type, iteration, hidden_unit_size,\n",
        "                                  sequence_name, type_of_ner):\n",
        "        \"\"\"save metrics of model\"\"\"\n",
        "        auc = roc_auc_score(ground_truth, probs)\n",
        "        auprc = average_precision_score(ground_truth, probs)\n",
        "        acc   = accuracy_score(ground_truth, predictions)\n",
        "        F1    = f1_score(ground_truth, predictions)\n",
        "\n",
        "        result_dict = {}\n",
        "        result_dict['auc'] = auc\n",
        "        result_dict['auprc'] = auprc\n",
        "        result_dict['acc'] = acc\n",
        "        result_dict['F1'] = F1\n",
        "\n",
        "        result_path = \"results/multimodal\"\n",
        "        file_name = str(sequence_name)+\"-\"+str(hidden_unit_size)+\"-\"+embed_name\n",
        "        file_name = file_name +\"-\"+problem_type+\"-\"+str(iteration)+\"-\"+type_of_ner+\"-avg-.p\"\n",
        "        pd.to_pickle(result_dict, os.path.join(result_path, file_name))\n",
        "\n",
        "        print(auc, auprc, acc, F1)\n",
        "\n",
        "    def avg_ner_model(self, layer_name, number_of_unit, embedding_name):\n",
        "        \"\"\"define the model specifications\"\"\"\n",
        "\n",
        "        #if embedding_name == \"concat\":\n",
        "        #    input_dimension = 200\n",
        "        #else:\n",
        "        #    input_dimension = 100\n",
        "        input_dimension = 100\n",
        "\n",
        "        sequence_input = Input(shape=(24,104))\n",
        "        input_avg = Input(shape=(input_dimension, ), name = \"avg\")\n",
        "\n",
        "        if layer_name == \"GRU\":\n",
        "            x = GRU(number_of_unit)(sequence_input)\n",
        "        elif layer_name == \"LSTM\":\n",
        "            x = LSTM(number_of_unit)(sequence_input)\n",
        "\n",
        "        x = keras.layers.Concatenate()([x, input_avg])\n",
        "        x = Dense(256, activation='relu')(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "\n",
        "        #logits_regularizer = tf.contrib.layers.l2_regularizer(scale=0.01)\n",
        "        logits_regularizer = keras.regularizers.l2(0.01)\n",
        "\n",
        "        preds = Dense(1, activation='sigmoid',use_bias=False,\n",
        "                      kernel_initializer=tf.keras.initializers.GlorotUniform(),\n",
        "                      kernel_regularizer=logits_regularizer)(x)\n",
        "\n",
        "        #opt = Adam(lr=0.001, decay = 0.01)\n",
        "        opt = tf.keras.optimizers.legacy.Adam(lr=0.001, decay = 0.01)\n",
        "        model = Model(inputs=[sequence_input, input_avg], outputs=preds)\n",
        "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc'])\n",
        "        return model\n",
        "\n",
        "    def train_models(self):\n",
        "        embedding_types = ['word2vec']\n",
        "        embedding_dict = [ner_word2vec]\n",
        "        #embedding_types = ['word2vec', 'fasttext', 'concat']\n",
        "        #embedding_dict = [ner_word2vec, ner_fasttext, ner_concat]\n",
        "        target_problems = ['mort_hosp', 'mort_icu', 'los_3', 'los_7']\n",
        "\n",
        "        num_epoch = 3\n",
        "        model_patience = 5\n",
        "        monitor_criteria = 'val_loss'\n",
        "        batch_size = 64\n",
        "        iter_num = 2\n",
        "        unit_sizes = [256]\n",
        "\n",
        "        layers = [\"GRU\"]\n",
        "        for each_layer in layers:\n",
        "            print (\"Layer: \", each_layer)\n",
        "            for each_unit_size in unit_sizes:\n",
        "                print (\"Hidden unit: \", each_unit_size)\n",
        "\n",
        "                for embed_dict, embed_name in zip(embedding_dict, embedding_types):\n",
        "                    print (\"Embedding: \", embed_name)\n",
        "                    print(\"=============================\")\n",
        "\n",
        "                    temp_train_ner = dict((k, ner_word2vec[k]) for k in train_ids)\n",
        "                    temp_dev_ner = dict((k, ner_word2vec[k]) for k in dev_ids)\n",
        "                    temp_test_ner = dict((k, ner_word2vec[k]) for k in test_ids)\n",
        "\n",
        "                    x_train_ner = self.create_dataset(temp_train_ner)\n",
        "                    x_dev_ner = self.create_dataset(temp_dev_ner)\n",
        "                    x_test_ner = self.create_dataset(temp_test_ner)\n",
        "\n",
        "                    for iteration in range(1, iter_num):\n",
        "                        print (\"Iteration number: \", iteration)\n",
        "\n",
        "                        for each_problem in target_problems:\n",
        "                            print (\"Problem type: \", each_problem)\n",
        "                            print (\"__________________\")\n",
        "\n",
        "                            early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
        "                            best_model_name = \"avg-\"+str(embed_name)+\"-\"+str(each_problem)+\"-\"+\"best_model.keras\"\n",
        "                            checkpoint = ModelCheckpoint(best_model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "                            callbacks = [early_stopping_monitor, checkpoint]\n",
        "\n",
        "                            model = self.avg_ner_model(each_layer, each_unit_size, embed_name)\n",
        "                            model.fit([x_train_lstm, x_train_ner], y_train[each_problem], epochs=num_epoch, verbose=1,\n",
        "                                      validation_data=([x_dev_lstm, x_dev_ner], y_dev[each_problem]), callbacks=callbacks,\n",
        "                                      batch_size=batch_size )\n",
        "\n",
        "                            model.load_weights(best_model_name)\n",
        "\n",
        "                            probs, predictions = self.make_prediction_multi_avg(model, [x_test_lstm, x_test_ner])\n",
        "\n",
        "                            #save_scores_multi_avg(predictions, probs, y_test[each_problem],\n",
        "                            #                      embed_name, each_problem, iteration, each_unit_size,\n",
        "                            #                      each_layer, type_of_ner)\n",
        "\n",
        "                            self.reset_keras(model)\n",
        "                            #del model\n",
        "                            clear_session()\n",
        "                            gc.collect()\n",
        "\n",
        "model = MultimodalModel(type_of_ner)\n",
        "model.train_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU4URWIvm71m"
      },
      "source": [
        "### 3. Proposed Model\n",
        "\n",
        "The proposed model further tries to improve upon the prediction performance of the 4 clinical tasks. We leverage 1D Convolutional Neural Networks (CNN) to extract features from medical entities, subsequently integrating them with recurrent and fully-connected layers for comprehensive patient representation. The CNN model uses 3 consecutive 1D convolutional layers of filter size 32, 64, and 96, plus a max-pooling layer at the end.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1B4oDgE3Zf8FQFQ68fngFSDEAloNsXSTy\"\n",
        "     align=\"center\"\n",
        "     width=\"700\" />\n",
        "\n",
        "Figure 4. Overview of the proposed CNN model architecture for predicting the In-Hospital Mortality, In-ICU Mortality, LOS >3, and LOS >7. The MIMIC-Extract pipeline extracts the time series features for the GRU model. We also pass the preprocessed clinical notes through med7 and different word embeddings to get the medical entity representations. A 1D CNN is then applied to get the final medical entity features. Finally, we combine the time-series features with the medical entity features to pass through a Dense layer (512 hidden units) in order to make a binary prediction on the 4 clinical tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moPFH7-Cd31h"
      },
      "outputs": [],
      "source": [
        "class ProposedModel:\n",
        "    def __init__(self, type_of_ner):\n",
        "        self.type_of_ner = type_of_ner\n",
        "\n",
        "    def make_prediction_cnn(self, model, test_data):\n",
        "        \"\"\"make model predictions\"\"\"\n",
        "        probs = model.predict(test_data)\n",
        "        y_pred = [1 if i>=0.5 else 0 for i in probs]\n",
        "        return probs, y_pred\n",
        "\n",
        "    def save_scores_cnn(self, predictions, probs, ground_truth,\n",
        "                        embed_name, problem_type, iteration, hidden_unit_size,\n",
        "                        sequence_name, type_of_ner):\n",
        "        \"\"\"save metrics from model predictions\"\"\"\n",
        "        auc = roc_auc_score(ground_truth, probs)\n",
        "        auprc = average_precision_score(ground_truth, probs)\n",
        "        acc   = accuracy_score(ground_truth, predictions)\n",
        "        F1    = f1_score(ground_truth, predictions)\n",
        "\n",
        "        result_dict = {}\n",
        "        result_dict['auc'] = auc\n",
        "        result_dict['auprc'] = auprc\n",
        "        result_dict['acc'] = acc\n",
        "        result_dict['F1'] = F1\n",
        "\n",
        "        result_path = \"results/cnn/\"\n",
        "        file_name = str(sequence_name)+\"-\"+str(hidden_unit_size)+\"-\"+embed_name\n",
        "        file_name = file_name +\"-\"+problem_type+\"-\"+str(iteration)+\"-\"+type_of_ner+\"-cnn-.p\"\n",
        "        pd.to_pickle(result_dict, os.path.join(result_path, file_name))\n",
        "\n",
        "        print(auc, auprc, acc, F1)\n",
        "\n",
        "    def print_scores_cnn(self, predictions, probs, ground_truth, model_name, problem_type, iteration, hidden_unit_size):\n",
        "        \"\"\"print metric scores\"\"\"\n",
        "        auc = roc_auc_score(ground_truth, probs)\n",
        "        auprc = average_precision_score(ground_truth, probs)\n",
        "        acc   = accuracy_score(ground_truth, predictions)\n",
        "        F1    = f1_score(ground_truth, predictions)\n",
        "\n",
        "        print (\"AUC: \", auc, \"AUPRC: \", auprc, \"F1: \", F1)\n",
        "\n",
        "    def get_subvector_data(self, size, embed_name, data):\n",
        "        \"\"\"get subvector data\"\"\"\n",
        "        #if embed_name == \"concat\":\n",
        "        #    vector_size = 200\n",
        "        #else:\n",
        "        #   vector_size = 100\n",
        "        vector_size = 100\n",
        "\n",
        "        x_data = {}\n",
        "\n",
        "        for k, v in data.items():\n",
        "            number_of_additional_vector = len(v) - size\n",
        "            vector = []\n",
        "            for i in v:\n",
        "                vector.append(i)\n",
        "            if number_of_additional_vector < 0:\n",
        "                number_of_additional_vector = np.abs(number_of_additional_vector)\n",
        "\n",
        "                temp = vector[:size]\n",
        "                for i in range(0, number_of_additional_vector):\n",
        "                    temp.append(np.zeros(vector_size))\n",
        "                x_data[k] = np.asarray(temp)\n",
        "            else:\n",
        "                x_data[k] = np.asarray(vector[:size])\n",
        "        return x_data\n",
        "\n",
        "    def proposedmodel(self, layer_name, number_of_unit, embedding_name, ner_limit, num_filter):\n",
        "        \"\"\"define model specifications\"\"\"\n",
        "        #if embedding_name == \"concat\":\n",
        "        #    input_dimension = 200\n",
        "        #else:\n",
        "        #    input_dimension = 100\n",
        "        input_dimension = 100\n",
        "\n",
        "        sequence_input = Input(shape=(24,104))\n",
        "        input_img = Input(shape=(ner_limit, input_dimension), name = \"cnn_input\")\n",
        "\n",
        "        convs = []\n",
        "        filter_sizes = [2,3,4]\n",
        "\n",
        "        text_conv1d = Conv1D(filters=num_filter, kernel_size=3,\n",
        "                             padding = 'valid', strides = 1, dilation_rate=1, activation='relu',\n",
        "                             kernel_initializer=tf.keras.initializers.GlorotUniform())(input_img)\n",
        "\n",
        "        text_conv1d = Conv1D(filters=num_filter*2, kernel_size=3,\n",
        "                             padding = 'valid', strides = 1, dilation_rate=1, activation='relu',\n",
        "                             kernel_initializer=tf.keras.initializers.GlorotUniform())(text_conv1d)\n",
        "\n",
        "        text_conv1d = Conv1D(filters=num_filter*3, kernel_size=3,\n",
        "                             padding = 'valid', strides = 1, dilation_rate=1, activation='relu',\n",
        "                             kernel_initializer=tf.keras.initializers.GlorotUniform())(text_conv1d)\n",
        "\n",
        "        text_embeddings = GlobalMaxPooling1D()(text_conv1d)\n",
        "\n",
        "        if layer_name == \"GRU\":\n",
        "            x = GRU(number_of_unit)(sequence_input)\n",
        "        elif layer_name == \"LSTM\":\n",
        "            x = LSTM(number_of_unit)(sequence_input)\n",
        "\n",
        "        concatenated = keras.layers.Concatenate()([x, text_embeddings])\n",
        "        concatenated = Dense(512, activation='relu')(concatenated)\n",
        "        concatenated = Dropout(0.2)(concatenated)\n",
        "\n",
        "        logits_regularizer = keras.regularizers.l2(0.01)\n",
        "        preds = Dense(1, activation='sigmoid',use_bias=False,\n",
        "                      kernel_initializer=tf.keras.initializers.GlorotUniform(),\n",
        "                      kernel_regularizer=logits_regularizer)(concatenated)\n",
        "\n",
        "        #opt = Adam(lr=1e-3, decay = 0.01)\n",
        "        opt = tf.keras.optimizers.legacy.Adam(lr=1e-3, decay = 0.01)\n",
        "\n",
        "        model = Model(inputs=[sequence_input, input_img], outputs=preds)\n",
        "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['acc'])\n",
        "        return model\n",
        "\n",
        "    def train_models(self):\n",
        "        embedding_types = ['word2vec']\n",
        "        embedding_dict = [ner_word2vec]\n",
        "        #embedding_types = ['word2vec', 'fasttext', 'concat']\n",
        "        #embedding_dict = [ner_word2vec, ner_fasttext, ner_concat]\n",
        "        target_problems = ['mort_hosp', 'mort_icu', 'los_3', 'los_7']\n",
        "\n",
        "        num_epoch = 3\n",
        "        model_patience = 5\n",
        "        monitor_criteria = 'val_loss'\n",
        "        batch_size = 64\n",
        "\n",
        "        filter_number = 32\n",
        "        ner_representation_limit = 64\n",
        "        activation_func = \"relu\"\n",
        "\n",
        "        sequence_model = \"GRU\"\n",
        "        sequence_hidden_unit = 256\n",
        "\n",
        "        maxiter = 2\n",
        "        for embed_dict, embed_name in zip(embedding_dict, embedding_types):\n",
        "            print (\"Embedding: \", embed_name)\n",
        "            print(\"=============================\")\n",
        "\n",
        "            temp_train_ner = {k: embed_dict[k] for k in train_ids if k in embed_dict}\n",
        "            temp_dev_ner = {k: embed_dict[k] for k in dev_ids if k in embed_dict}\n",
        "            temp_test_ner = {k: embed_dict[k] for k in test_ids if k in embed_dict}\n",
        "\n",
        "            x_train_dict = {}\n",
        "            x_dev_dict = {}\n",
        "            x_test_dict = {}\n",
        "\n",
        "            x_train_dict = self.get_subvector_data(ner_representation_limit, embed_name, temp_train_ner)\n",
        "            x_dev_dict = self.get_subvector_data(ner_representation_limit, embed_name, temp_dev_ner)\n",
        "            x_test_dict = self.get_subvector_data(ner_representation_limit, embed_name, temp_test_ner)\n",
        "\n",
        "            # Sort dictionaries and convert values to NumPy arrays\n",
        "            x_train_dict_sorted = {k: v for k, v in sorted(x_train_dict.items())}\n",
        "            x_dev_dict_sorted = {k: v for k, v in sorted(x_dev_dict.items())}\n",
        "            x_test_dict_sorted = {k: v for k, v in sorted(x_test_dict.items())}\n",
        "\n",
        "            x_train_ner = np.asarray(list(x_train_dict_sorted.values()))\n",
        "            x_dev_ner = np.asarray(list(x_dev_dict_sorted.values()))\n",
        "            x_test_ner = np.asarray(list(x_test_dict_sorted.values()))\n",
        "\n",
        "            for iteration in range(1,maxiter):\n",
        "                print (\"Iteration number: \", iteration)\n",
        "\n",
        "                for each_problem in target_problems:\n",
        "                    print (\"Problem type: \", each_problem)\n",
        "                    print (\"__________________\")\n",
        "\n",
        "                    early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
        "                    best_model_name = str(ner_representation_limit)+\"-basiccnn1d-\"+str(embed_name)+\"-\"+str(each_problem)+\"-\"+\"best_model.keras\"\n",
        "                    checkpoint = ModelCheckpoint(best_model_name, monitor=monitor_criteria, verbose=1, save_best_only=True, mode='min')\n",
        "                    reduce_lr = ReduceLROnPlateau(monitor=monitor_criteria, factor=0.2, patience=2, min_lr=0.00001, min_delta=1e-4, mode='min')\n",
        "                    callbacks = [early_stopping_monitor, checkpoint, reduce_lr]\n",
        "\n",
        "                    model = self.proposedmodel(sequence_model, sequence_hidden_unit, embed_name, ner_representation_limit,filter_number)\n",
        "                    model.fit([x_train_lstm, x_train_ner], y_train[each_problem], epochs=num_epoch, verbose=1,\n",
        "                              validation_data=([x_dev_lstm, x_dev_ner], y_dev[each_problem]), callbacks=callbacks, batch_size=batch_size)\n",
        "\n",
        "                    probs, predictions = self.make_prediction_cnn(model, [x_test_lstm, x_test_ner])\n",
        "                    #self.print_scores_cnn(predictions, probs, y_test[each_problem], embed_name, each_problem, iteration, sequence_hidden_unit)\n",
        "\n",
        "                    model.load_weights(best_model_name)\n",
        "\n",
        "                    probs, predictions = self.make_prediction_cnn(model, [x_test_lstm, x_test_ner])\n",
        "                    #self.save_scores_cnn(predictions, probs, y_test[each_problem], embed_name, each_problem, iteration,\n",
        "                    #                sequence_hidden_unit, sequence_model, type_of_ner)\n",
        "                    del model\n",
        "                    clear_session()\n",
        "                    gc.collect()\n",
        "\n",
        "model = ProposedModel(type_of_ner)\n",
        "model.train_models()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv5NCgolTDz6"
      },
      "source": [
        "## Training\n",
        "\n",
        "**Setting**\n",
        "\n",
        "Each of the models underwent training for 100 epochs with 10 iterations. Notably, the average runtime for each epoch was impressively fast, requiring only a few seconds, approximately 15 seconds on average. In total, the project consumed approximately 25 hours, with approximately 21 hours allocated to the Med7 application on clinical notes, and the remaining hours divided among training and testing time series models, multimodal models, and the proposed model.\n",
        "\n",
        "For the purpose of comparing the effectiveness of the proposed model enhancements, we trained the timeseries baseline model and the multimodal baseline model exclusively with a GRU layer featuring 256 units.\n",
        "\n",
        "The hyperparameters used in the proposed model include:\n",
        "- stack of 3 1-D convolution layers, ReLU activation, filter size=[32, 64, 96], kernel size=3, followed by max pooling layer\n",
        "- the features in the max pooling layer are combined with the features of 1 layer GRU of 256 hidden units and has a Dense layer (units=512, ReLU activation) and a Dropout layer with p=0.2.\n",
        "- training the model used a batch size of 64, an Adam optimizer (learning rate=0.001, decay=0.1) and binary cross entropy loss function.\n",
        "\n",
        "The code for model training is included in each models' class function, in the 'Model' section of this notebook. The training results are saved in the results folder.\n",
        "\n",
        "**Computation Details**\n",
        "\n",
        "The paper suggests the computational requirements needed is a NVIDIA Tesla K80 GPU with 24 GB of VRAM, 378 GB of RAM and Intel Xeon E5 2683 processor [1]. Because the MIMIC-III dataset is so large, we ran the data preprocessing and training/testing of each model in separate Jupyter notebooks stored locally on a PC with Nvidia GeForce RTX 3080 Ti (GPU) containing 16 GB of GDDR6 VRAM, 32GB of DDR5 RAM and Intel i9-12900H processor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMoKaBruTInf"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "We will be using 3 different statistical methods for the comparison of our models.\n",
        "* Area Under the Receiver Operating Characteristic curve (AUROC), which is the area under the true positive rate versus the false positive rate.\n",
        "* Area Under the Precision-Recall Curve (AUPRC), which is the area under\n",
        "the precision versus recall plot.\n",
        "* F1 score measures accuracy by considering both precision and recall to compute the score, providing a balance between false positives and false negatives.\n",
        "\n",
        "The evaluation code is provided as a function in each models' class, named similar to save_scores().\n",
        "\n",
        "The results are then averaged across the 10 iterations for each performance metric and clinical task. The average and standard deviation are reported below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For the Time Series Baseline model\n",
        "print(\"Time Series Baseline Model: Average +- Std Dev of Performance Metrics for Predicting Clinical Tasks\")\n",
        "\n",
        "# Define categories and metrics\n",
        "categories = [\"256-GRU\"]\n",
        "metrics = {\"auc\":\"AUROC\", \"auprc\":\"AUPRC\", \"acc\":\"Accuracy\", \"F1\":\"F1\"}\n",
        "tasks = [\"mort_hosp\", \"mort_icu\", \"los_3\", \"los_7\"]\n",
        "\n",
        "# Initialize dictionaries to store results\n",
        "results = {category: {task: {metric_name: [] for metric, metric_name in metrics.items()} for task in tasks} for category in categories}\n",
        "\n",
        "# Directory where pickle files are stored\n",
        "directory = \"/content/drive/MyDrive/CS598_Project/results/\"\n",
        "\n",
        "# Loop through each file\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".p\"):\n",
        "        parts = filename.split(\"-\")\n",
        "        category = parts[0] + \"-\" + parts[1]\n",
        "        task = parts[2]\n",
        "        if category in categories and task in tasks:\n",
        "            result_dict = pd.read_pickle(os.path.join(directory, filename))\n",
        "            for metric, metric_name in metrics.items():\n",
        "                results[category][task][metric_name].append(result_dict[metric])\n",
        "\n",
        "# Calculate average and standard deviation\n",
        "for category in categories:\n",
        "    print(f\"Model: {category}\")\n",
        "    df_data = {task: {} for task in tasks}\n",
        "    for task in tasks:\n",
        "        task_data = {}\n",
        "        for metric, metric_name in metrics.items():\n",
        "            values = results[category][task][metric_name]\n",
        "            mean = np.mean(values)\n",
        "            std = np.std(values)\n",
        "            task_data[metric_name] = f\"{mean:.4f} \\u00B1 {std:.4f}\"\n",
        "        df_data[task] = task_data\n",
        "    df = pd.DataFrame(df_data).transpose()\n",
        "    print(df)\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "Y69mKUOLx2Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the Multimodal Baseline model\n",
        "print(\"Multimodal Baseline Model: Average +- Std Dev of Performance Metrics for Predicting Clinical Tasks Using Different Embeddings\")\n",
        "\n",
        "# Define categories and metrics\n",
        "categories = [\"GRU-256\"]\n",
        "metrics = {\"auc\":\"AUROC\", \"auprc\":\"AUPRC\", \"acc\":\"Accuracy\", \"F1\":\"F1\"}\n",
        "tasks = [\"mort_hosp\", \"mort_icu\", \"los_3\", \"los_7\"]\n",
        "embeddings = [\"word2vec\", \"fasttext\", \"concat\"]\n",
        "\n",
        "# Initialize dictionaries to store results\n",
        "results = {category: {embedding: {task: {metric_name: [] for metric, metric_name in metrics.items()} for task in tasks} for embedding in embeddings} for category in categories}\n",
        "\n",
        "# Directory where pickle files are stored\n",
        "directory = \"/content/drive/MyDrive/CS598_Project/results/multimodal/\"\n",
        "\n",
        "# Loop through each file\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\"-new-avg-.p\"):\n",
        "        parts = filename.split(\"-\")\n",
        "        category = parts[0] + \"-\" + parts[1]\n",
        "        embedding = parts[2]\n",
        "        task = parts[3]\n",
        "        if category in categories and task in tasks and embedding in embeddings:\n",
        "            result_dict = pd.read_pickle(os.path.join(directory, filename))\n",
        "            for metric, metric_name in metrics.items():\n",
        "                results[category][embedding][task][metric_name].append(result_dict[metric])\n",
        "\n",
        "# Calculate average and standard deviation\n",
        "for category in categories:\n",
        "    print(f\"Model: {category}\")\n",
        "    for embedding in embeddings:\n",
        "        print(f\"Embedding: {embedding}\")\n",
        "        df_data = {task: {} for task in tasks}\n",
        "        for task in tasks:\n",
        "            task_data = {}\n",
        "            for metric, metric_name in metrics.items():\n",
        "                values = results[category][embedding][task][metric_name]\n",
        "                mean = np.mean(values)\n",
        "                std = np.std(values)\n",
        "                task_data[metric_name] = f\"{mean:.4f} \\u00B1 {std:.4f}\"\n",
        "            df_data[task] = task_data\n",
        "        df = pd.DataFrame(df_data).transpose()\n",
        "        print(df)\n",
        "        print()"
      ],
      "metadata": {
        "id": "L-_TP5Gwx2gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the Proposed CNN model\n",
        "print(\"Proposed CNN Model: Average +- Std Dev of Performance Metrics for Predicting Clinical Tasks Using Different Embeddings\")\n",
        "\n",
        "# Define categories and metrics\n",
        "categories = [\"GRU-256\"]\n",
        "metrics = {\"auc\":\"AUROC\", \"auprc\":\"AUPRC\", \"acc\":\"Accuracy\", \"F1\":\"F1\"}\n",
        "tasks = [\"mort_hosp\", \"mort_icu\", \"los_3\", \"los_7\"]\n",
        "embeddings = [\"word2vec\", \"fasttext\", \"concat\"]\n",
        "\n",
        "# Initialize dictionaries to store results\n",
        "results = {category: {embedding: {task: {metric_name: [] for metric, metric_name in metrics.items()} for task in tasks} for embedding in embeddings} for category in categories}\n",
        "\n",
        "# Directory where pickle files are stored\n",
        "directory = \"/content/drive/MyDrive/CS598_Project/results/cnn/\"\n",
        "\n",
        "# Loop through each file\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\"-new-cnn-.p\"):\n",
        "        parts = filename.split(\"-\")\n",
        "        category = parts[0] + \"-\" + parts[1]\n",
        "        embedding = parts[2]\n",
        "        task = parts[3]\n",
        "        if category in categories and task in tasks and embedding in embeddings:\n",
        "            result_dict = pd.read_pickle(os.path.join(directory, filename))\n",
        "            for metric, metric_name in metrics.items():\n",
        "                results[category][embedding][task][metric_name].append(result_dict[metric])\n",
        "\n",
        "# Calculate average and standard deviation\n",
        "for category in categories:\n",
        "    print(f\"Model: {category} + CNN\")\n",
        "    for embedding in embeddings:\n",
        "        print(f\"Embedding: {embedding}\")\n",
        "        df_data = {task: {} for task in tasks}\n",
        "        for task in tasks:\n",
        "            task_data = {}\n",
        "            for metric, metric_name in metrics.items():\n",
        "                values = results[category][embedding][task][metric_name]\n",
        "                mean = np.mean(values)\n",
        "                std = np.std(values)\n",
        "                task_data[metric_name] = f\"{mean:.4f} \\u00B1 {std:.4f}\"\n",
        "            df_data[task] = task_data\n",
        "        df = pd.DataFrame(df_data).transpose()\n",
        "        print(df)\n",
        "        print()"
      ],
      "metadata": {
        "id": "M6dzCn8Ux2k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX6bCcZNuxmz"
      },
      "source": [
        "## Results\n",
        "\n",
        "We organized our result comparison to mirror the format of the original paper. First, we assessed baseline models using essential metrics: AUROC, AUPRC, and F1 scores. We highlighted the best-performing metrics for each task in the initial table. Then, we compared the top scores of the baseline models with those of our proposed model, showcasing the superior score for each task in the subsequent table.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1-78qDJq4KP0gZ153nguy5dRz14-EdXW3\"\n",
        "     align=\"center\"\n",
        "     width=\"700\" />\n",
        "\n",
        "Table 1. Statistical summary of prediction results using baseline model and baseline multimodal architecture\n",
        "\n",
        "**Baseline Model Results**\n",
        "\n",
        "We predict four clinical tasks with the patient's first 24 hours ICU measurements and medical entities. Table 1 summarizes the overall performance of the baseline models.\n",
        "\n",
        "*  Across all four clinical task predictions, the multimodal baseline model consistently outperformed the GRU baseline model. This aligns with our hypothesis as well as the original paper. We observed the most significant improvements in AUPRC and F1 for predicting In-Hospital Mortality and In-ICU Mortality.\n",
        "* Comparing the reproduced baseline model results with those of the original paper, we observed improvements in all baseline model metrics. We suspect that discrepancies in library versions, embeddings, and dataset configurations might have contributed to these improvements.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1yFt5YU-BXQdZKAN5EWHwACYeZIZzilsL\"\n",
        "     align=\"center\"\n",
        "     width=\"700\" />\n",
        "\n",
        "Table 2. Statistical summary of prediction results using the best baseline model obtained from Table 1 and the proposed model\n",
        "\n",
        "**Proposed Model Results**\n",
        "\n",
        "We compare the result of the proposed model against the best scores taken from the baseline models. Table 2 presents all outcomes from the proposed model in contrast to the best baseline scores.\n",
        "\n",
        "*   The proposed model yielded similar results as the best baseline metrics. In the task of predicting Length of Stay (LOS) exceeding 7 days, we observed enhancements in both AUROC and AUPRC with the utilization of Word2Vec embeddings.\n",
        "*  Comparing the reproduced results of the proposed model with those reported in the original paper, we once again observed improvements across all proposed model metrics.\n",
        "*  In the reproduced results, while the proposed model demonstrated comparable performance to the best baseline model, the anticipated significant improvements in the performance metrics compared to the best baseline score were not observed, which contradicts our initial hypothesis. We suspect several reasons for this disparity:\n",
        "  1.  Upon comparing the reproduced results of both the baseline and proposed models to those reported in the original paper, we observed improvements across all four tasks for both models. Additionally, the best baseline scores are significantly higher than the ones from the paper. This observation raises the possibility that the proposed model may reach a performance plateau once it attains a certain level of improvement.\n",
        "  2.   Discrepancies in library versions, embeddings, and dataset configurations may have hindered our ability to replicate similar results.\n",
        "\n",
        "\n",
        "**Abalation Study**\n",
        "\n",
        "In our conducted ablation study, we compared the performance of the proposed convolution-based GRU multimodal architecture with the baseline GRU architecture. We utilized three different embedding techniques - word2vec, fasttext, and a combination of the two - in predicting four distinct clinical tasks. The baseline models comprised of both the GRU architecture and GRU multimodal architecture, utilizing the abovementioned embeddings.\n",
        "\n",
        "Our findings revealed that the addition of a CNN layer led to performance enhancements in one out of the four prediction tasks. Specifically, when predicting Length of Stay (LOS) exceeding 7 days, we observed improvements in both AUROC and AUPRC with the incorporation of word2vec embeddings. This suggests that the CNN layer may be advantageous for improving the prediction of LOS > 7 Days, although its benefits may not extend uniformly across all tasks, especially when baseline scores already exhibit high performance levels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH75TNU71eRH"
      },
      "source": [
        "## Discussion\n",
        "\n",
        "**Implications of the Result**\n",
        "\n",
        "When comparing the results of our baseline and proposed models with those reported in the original paper, we noticed similar performance metrics, with our reproduced results showing slight improvements.\n",
        "\n",
        "When comparing across prediction tasks, we observed superior performance in predicting mortality, especially when representing medical entities using the averaging method. Regarding the three different embeddings, in Table 1, fasttext consistently yielded the best baseline scores. However, in Table 2, we noted that word2vec embeddings achieved higher scores than fasttext and the combination, which is consistent with the observations reported in the paper.\n",
        "\n",
        "When comparing our best baseline scores with those of the proposed model, we only observed improvement in 1 out of 4 prediction tasks, which deviates from the findings of the original paper. We attribute this deviation  to changes we made in the code, including the removal of deprecated methods in Keras and TensorFlow libraries, as well as differences in fasttext embeddings (as the original embeddings from the GitHub repository were missing), and discrepancies in library versions.\n",
        "\n",
        "**Reproducibility**\n",
        "\n",
        "In general, we were able to reproduce comparable results, largely thanks to the availability of the original code and comprehensive documentation outlining preprocessing steps and environment setup.\n",
        "\n",
        "However, several factors posed challenges to reproduction:\n",
        "* Downloading large datasets like MIMIC-III and obtaining pre-trained models from various sources proved to be time-consuming.\n",
        "* Data preprocessing took considerably longer than anticipated. For instance, extracting medical entities using Word2Vec required over 20 hours.\n",
        "* Accessing the Fasttext embedding posed difficulties as it was not readily available in the original repository download link provided by the author. Eventually, we located it in the comments section of the Issues tab in the paper's GitHub repository.\n",
        "* The original code contained deprecated methods from Keras and Tensorflow, as well as unused or outdated imported libraries (e.g., Glove), leading to compatibility and functionality issues.\n",
        "\n",
        "To enhance reproducibility, we recommend including estimates of the time required for each preprocessing step, embedding technique implementation, model training, etc. Additionally, maintaining up-to-date dependencies and promptly removing deprecated methods would streamline the reproduction process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHMI2chl9omn"
      },
      "source": [
        "# References\n",
        "\n",
        "1. Bardak B, Tan M, \"Improving clinical outcome predictions using convolution over medical entities with multimodal learning\", Artificial Intelligence in Medicine, 2021, 117:0933-3657, doi:https://doi.org/10.1016/j.artmed.2021.102112.\n",
        "2. Johnson A, Pollard T, Mark R, \"MIMIC-III Clinical Database (version 1.4)\", PhysioNet, 2016, doi:https://doi.org/10.13026/C2XW26.\n",
        "3. Johnson AEW, Pollard TJ, Shen L, Lehman LH, Feng M, Ghassemi M, Moody B, Szolovits P, Celi L A, Mark RG, \"MIMIC-III, a freely accessible critical care database\", Scientific Data, 2016, 3:160035.\n",
        "4. Goldberger A, Amaral L, Glass L, Hausdorff J, Ivanov PC, Mark R, ... & Stanley HE, \"PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals\", Circulation [Online], 2000, 101:23, pp. e215â€“e220.\n",
        "5. Choi E, Bahadori MT, Schuetz A, Stewart WF, Sun J. Doctor AI: predicting clinical events via recurrent neural networks. Machine learning for healthcare conference 2016:301-18.\n",
        "6. Choi E, Bahadori MT, Sun J, Kulas J, Schuetz A, Stewart W. Retain: an interpretable predictive model for healthcare using reverse time attention mechanism. Advances in neural information processing systems. 2016. p. 3504-12.\n",
        "7. Caballero Barajas KL, Akella R. Dynamically modeling patientâ€™s health state from electronic medical records: a time series approach. Proceedings of the 21st ACM SIGKDD international conference on knowledge discovery and data mining 2015:69â€“78.\n",
        "8. Song H, Rajan D, Thiagarajan JJ, Spanias A. Attend and diagnose: clinical time series analysis using attention models. Thirty-second AAAI conference on artificial intelligence 2018.\n",
        "9. Suresh H, Gong JJ, Guttag JV. Learning tasks for multitask learning: heterogenous patient populations in the ICU. Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining 2018:802â€“10.\n",
        "10. Lipton ZC, Kale DC, Elkan C, Wetzel R. Learning to diagnose with LSTM recurrent neural networks. 2015 (arXiv preprint), arXiv:1511.03677.\n",
        "11. Wang S, McDermott MBA, Chauhan G, Hughes MC, Naumann T, Ghassemi M. MIMIC-Extract: A Data Extraction, Preprocessing, and Representation\n",
        "Pipeline for MIMIC-III. arXiv:1907.08322.\n",
        "12. Kormilitzin A, Vaci N, Liu Q, Nevado-Holgado A. Med7: A Transferable Clinical Natural Language Processing Model for Electronic Health Records. 2020. arXiv:2003.01271.\n",
        "13. Huang K, Altosaar J, Ranganath R. ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission. 2019. arXiv:1904.05342\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}